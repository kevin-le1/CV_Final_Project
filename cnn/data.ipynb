{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset plastic_in_river (/Users/kevin/.cache/huggingface/datasets/Kili___plastic_in_river/default/1.3.0/9f50c1fffe85018c95137b17f0e5a271be58507e17e7a3f3a4075f763c20b8de)\n",
      "100%|██████████| 3/3 [00:00<00:00, 19.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'litter'],\n",
      "        num_rows: 3407\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'litter'],\n",
      "        num_rows: 427\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'litter'],\n",
      "        num_rows: 425\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('Kili/plastic_in_river', num_proc=6)\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm  # Import tqdm from tqdm.notebook module\n",
    "\n",
    "# only creating datasets for train and validation not test\n",
    "os.makedirs('datasets/images/train', exist_ok=True)\n",
    "os.makedirs('datasets/images/test', exist_ok=True)\n",
    "os.makedirs('datasets/images/validation', exist_ok=True)\n",
    "\n",
    "\n",
    "os.makedirs('datasets/labels/train', exist_ok=True)\n",
    "os.makedirs('datasets/labels/test', exist_ok=True)\n",
    "os.makedirs('datasets/labels/validation', exist_ok=True)\n",
    "\n",
    "def create_dataset(data, split):\n",
    "    data = data[split]\n",
    "  \n",
    "    print(f'Running for {split} split...')\n",
    "  \n",
    "    for idx, sample in enumerate(data):\n",
    "        image = sample['image']\n",
    "        labels = sample['litter']['label']\n",
    "        bboxes = sample['litter']['bbox']\n",
    "        targets = []\n",
    "        if(len(labels) > 0):\n",
    "            class_id = 0\n",
    "        else:\n",
    "            class_id = 2\n",
    "    \n",
    "    # creating the label txt files\n",
    "    for label, bbox in zip(labels, bboxes):\n",
    "        targets.append(f'{label} {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]} {class_id}')\n",
    "      \n",
    "    with open(f'datasets/labels/{split}/{idx}.txt', 'w') as f:\n",
    "        for target in targets:\n",
    "            f.write(target + '\\n')\n",
    "        \n",
    "    # saving image to png\n",
    "    image.save(f'datasets/images/{split}/{idx}.png')\n",
    "\n",
    "create_dataset(dataset, 'train')\n",
    "create_dataset(dataset, 'test')\n",
    "create_dataset(dataset, 'validation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5307e98954c1652c3564abd66d0211a7c00ac63b2731b8c6069a552ec199cec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
